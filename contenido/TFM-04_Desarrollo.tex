\chapter{Desarrollo}\label{chap:desarrollo}
\textbf{Desarrollo específico de la contribución}

%Párrafo introductorio del capítulo
[Párrafo introductorio del capítulo. Lorem ipsum dolor sit amet, consectetur adipisicing elit. Natus impedit sint cumque, omnis assumenda, molestias corporis repellat, reprehenderit, ullam labore aliquam. Velit ut, ab amet a recusandae, eaque similique alias!]

\section{Presentación del entorno}\label{sec:presentaciondelentorno}

En el escenario del proyecto (la red de un banco que es cliente de la empresa), [..]

\section{Extracción y filtrado}\label{sec:extraccionyfiltrado}

El punto de interés para la captura se concentra por tanto en dos equipos por los que pasa el grueso del tráfico total: un Firewall Fortinet y un IPS PaloAlto.
Como es habitual, estos equipos reportan todas sus acciones a través de logs, con varios niveles de granularidad e importancia.
Incluyen también multitud de información aportada por los propios sistemas que enriquecen el valor de cada evento.
Esto es razón para preferir los logs de firewall como fuente de información frente a una captura de tráfico en crudo, ya que
lo que procesan los firewalls casi siempre es más relevante que el tráfico completo pero sin procesar.
Además, el volumen de una captura de tráfico de estas características sería notablemente mayor y más difícil de manejar.

Aunque el fin para el que sirven ambos equipos (análisis y protección frente a amenazas informáticas) sea similar,
la estructura usada por cada uno en los logs que produce es completamente distinta.
Los logs de Fortinet siguen un formato clave-valor con ciertas particularidades, mientras que los de PaloAlto tienen una serie de campos fijos que están delimitados por comas. A modo de ejemplo, las dos líneas adjuntadas a continuación corresponden a un evento del firewall Fortinet y otro del IPS PaloAlto, respectivamente (cada evento viene en una única línea):

\begingroup
\makeatletter
\@totalleftmargin=-1cm
\begin{verbatim}

1585572524|1585572524|2020-03-30T06:48:44.202297|10.2.0.11|6|local7|
date=2020-03-30 time=06:48:44 devname="FW1_INTERNETCORP" devid="FG1809999"
logid="1059028704" type="utm" subtype="app-ctrl" eventtype="app-ctrl-all"
level="information" vd="root" eventtime=1585572524 appid=41470 user="NOM"
group="GrupoOffice365" authserver="SV1" srcip=172.2.9.6 dstip=23.203.51.72
srcport=54697 dstport=443 srcintf="p18" srcintfrole="undef" dstintf="p20"
dstintfrole="wan" proto=6 service="HTTPS" direction="outgoing" policyid=124
sessionid=325186437 applist="AC_CORREO" appcat="Collab" app="Microsoft.CDN"
action="pass" hostname="img-prod-cms-rt-microsoft-com.akamaized.net"
incidentserialno=1513678724 url="/" msg="Collaboration: Microsoft.CDN,"
apprisk="elevated" scertcname="a248.e.akamai.net"

1585659863|1585659863|2020-03-31T07:04:23.027791|10.2.0.73|6|local0|
1,2020/03/31 07:04:23,001801037558,TRAFFIC,end,2049,2020/03/31 07:04:03,
10.138.4.7,186.151.236.155,0.0.0.0,0.0.0.0,OUTBOUND,,,incomplete,vsys1,
trust,untrust,ethernet1/10,ethernet1/9,Log-Panorama,2020/03/31 07:04:03,
41602,1,55074,80,0,0,0x19,tcp,allow,132,132,0,2,2020/03/31 07:03:55,3,any,
0,1307298109,0x80000,10.0.0.0-10.255.255.255,America,0,2,0,aged-out,13,0,0,
0,,PA-3020-Z9,from-policy,,,0,,0,,N/A,0,0,0,0

\end{verbatim}
\endgroup

[Volumen de estos logs]

[Gráfica de volumen acumulado en el tiempo]

Otro hecho reseñable que afecta al formato es que se emplea \emph{syslog}\footnote{\url{https://tools.ietf.org/html/rfc5424}} (el estándar de facto) como protocolo para trasladar los datos desde cada equipo hasta la sonda, de forma que se cuenta con ciertos campos adicionales a los enviados por los equipos.
Para el tema que nos ocupa, los únicos campos que se extraen de esta cabecera son: la marca de tiempo en la que ha llegado cada evento, conocida en el vocabulario informático como \emph{timestamp}, y la prioridad del evento.
En cualquier caso, esta sección adicional dentro de los logs tiene también su propio formato, por lo cual también se deberá tratar de forma específica.
En nuestra configuración (que aplica a la herramienta \emph{rsyslog}\footnote{\url{https://www.rsyslog.com/}}), la siguiente directiva establece cómo se vuelcan a fichero estos campos de syslog:

\begin{verbatim}
template(name="FORMATO_LOGS" type="string"
string="%timereported:::date-unixtimestamp%
    |%timegenerated:::date-unixtimestamp%
    |%timegenerated:::date-rfc3339%|%fromhost-ip%
    |%syslogseverity%|%syslogfacility-text%| %syslogtag%%msg%\n")
\end{verbatim}

Así que, en los \emph{scripts} que procesan los ficheros donde se han volcado los datos traídos mediante \emph{syslog}, se obtiene la fecha de cada evento a partir de este primer campo ``timereported:::date-unixtimestamp'' y la prioridad a partir del quinto campo.
Esta primera parte del procesado (que está programado en Python) se hace de la siguiente manera:

\begin{minted}{python}
for syslogline in sys.stdin:

    try:

        splitted_syslogline = syslogline.rstrip().split("|") # .rstrip() removes last "\n" character

        tstamp_line = int(splitted_syslogline[0])

        prio = splitted_syslogline[4]
\end{minted}

Seguidamente, el resto de la línea actual (sin la cabecera de \emph{syslog}) se convierte en una estructura de diccionario.
Como se apreciaba en las líneas de ejemplo que se han incluido antes, la relación entre claves y valores depende de cada caso.

Para el equipo Fortinet, la relación está definida en el propio evento como \texttt{clave="valor"} o \texttt{clave=valor} para valores no considerados como cadenas de texto.
Cabe destacar que el símbolo ``\texttt{=}'' puede estar contenido en el valor.
El nombre de la clave, sin embargo, nunca llevará comillas.
Establecidas las anteriores reglas, en Fortinet se convierten los campos con una expresión regular y una \emph{dict comprehension}\footnote{\url{https://www.python.org/dev/peps/pep-0274/}}
(es decir, una forma concisa de crear diccionarios a través de la iteración sobre una lista con la posibilidad de incluir condicionales):

\begin{minted}{python}
    line = "".join(splitted_syslogline[6:]) # removes "1581410810|1581410810|2020-02-11T02:46:51.421302|10.25.0.6|5|local7|"

    fields = re.split("([^ \"]+=[^ \"]+)|([^ \"]+=\"[^\"]+\")", line)

    dict_line = {k:v.strip('"')
                 for k,v in [f.split("=", 1)
                 for f in fields if (f and "=" in f)]}
\end{minted}

Para el IPS PaloAlto, la extracción de los campos es más sencilla.
Como cumplen con el formato CSV estandarizado\footnote{\url{https://tools.ietf.org/html/rfc4180}}, los valores se tienen en una lista con solo leer la línea a través de una función de la librería \texttt{csv}.
En cuanto a las claves, en la documentación\footnote{\url{https://docs.paloaltonetworks.com/pan-os/8-1/pan-os-admin/monitoring/use-syslog-for-monitoring/syslog-field-descriptions.html}}
de PaloAlto se explica que depende del tipo del evento.
Por tanto, se asignan unas claves u otras consultando primero de qué tipo se trata.
Finalmente, se construye el diccionario con otra \emph{dict comprehension}:

\begin{minted}{python}
    line = "".join(splitted_syslogline[6:]) # removes "1581410810|1581410810|2020-02-11T02:46:51.421302|10.25.0.6|5|local7|"

    values = list( csv.reader([line]) )[0]

    this_type_keys = []

    if values[3]=="TRAFFIC": # type is on 4th field
        this_type_keys.extend(common_trafficthreat_fields)
        this_type_keys.extend(traffic_fields)
    elif values[3]=="THREAT":
        ...

    if this_type_keys!=[]:
        dict_line = {k:v for k,v in zip(this_type_keys,values)}
\end{minted}

Posteriormente se lleva a cabo otra serie de operaciones necesarias para la transformación de los datos de entrada en información útil para la monitorización.
Sin embargo, desde la perspectiva de este trabajo, el único apartado de interés es la agregación de sesiones, que se desarrolla a continuación.

Una parte de este procesado consiste en guardar cierta información asociada a cada sesión.
El concepto de ``sesión'' sería equivalente al de ``flujo'' presentado en el \hyperref[chap:estadodelarte]{capítulo anterior}:
una serie de eventos asociados que se corresponden con la misma tupla de \{IP origen, IP destino, protocolo, puerto origen, puerto destino\}.
Los dos equipos mantienen un campo ``Identificador de Sesión'' interno que se añade a la tupla de la sesión.
Este campo permite distinguir los eventos de sesiones que coinciden en origen y destino pero se producen en intervalos temporales diferentes.
Se incluye en el procesado con esta finalidad de no confundir sesiones distintas en etapas posteriores, pero para nuestro propósito de clasificación de equipos puede ignorarse.

La información de cada sesión se compone de:
\begin{itemize}
    \item Tupla que define la sesión:\\\{ID de sesión, IP origen, IP destino, protocolo, puerto origen, puerto destino\}
    \item Timestamps del primer y último evento pertenecientes a esta sesión
    \item Máxima prioridad de evento vista en esta sesión
    \item Bytes recibidos y enviados (solo en el IPS)
    \item Nivel de anomalía
    \item Nivel de amenaza
    \item Contador y lista de eventos
\end{itemize}

Los niveles de anomalía y amenaza son unos índices simples que se han diseñado para resumir cualidades de la sesión de interés, como son
cuánto se aleja de la normalidad la cantidad de eventos prioritarios que se han visto y cómo son de peligrosas las amenazas recibidas.
Se calculan con las fórmulas:

\begin{eqnarray*}
    & N_{\textrm{anomalía}} = \sum \frac{1}{\textrm{prioridad\_evento}}\\
    & \textrm{para eventos de prioridad }\leq4\textrm{ o eventos de tráfico que no son de inicio ni fin}
\end{eqnarray*}

\begin{eqnarray*}
    & N_{\textrm{amenaza}} = \sum \frac{1}{\textrm{prioridad\_evento}}\\
    & \textrm{para eventos de amenaza con prioridad }\leq4\textrm{ que no son bloqueados}
\end{eqnarray*}

Tanto estas como el resto de características cuantificables pueden resultar de interés a la hora de aplicar \emph{clustering} sobre un dataset derivado de este procesado.

La recolección de esta información se realiza a través de la función adjunta.
Como puede verse, cuando se llama a esta función (lo cual ocurre ante todos los eventos de protocolo TCP o UDP que incluyan ID de sesión)
se actualizan los parámetros relativos a la sesión actual, que están almacenados en un diccionario.
A su vez, este diccionario se encuentra dentro del diccionario \texttt{sessions}.
Este mantiene en memoria todas las sesiones que todavía no se han cerrado.
Cuando transcurre un \emph{bucket} de tiempo determinado (por defecto, 60 segundos), se comprueban todas las sesiones vigentes.
Aquellas que tienen un evento de finalización se imprimen en un fichero y se borran del diccionario \texttt{sessions}.
De este modo, cada 60 segundos se tienen nuevas sesiones completas (se alcanzan incluso más de 100 000 sesiones finalizadas cada minuto)
que servirán de datos de entrada para el módulo de \emph{clustering}.

\begin{minted}{python}
def session_aggregation(dict_line, event_descript, event_tstamp):
    """
    It groups info related to actual session on the sessions dictionary, that is:
    - the sessionid and the session tuple (srcip-dstip-proto-srcport-dstport)
    - tstamp of first and last event observed for actual session
    - update max. priority of events observed for actual session
    - sent and received bytes for actual session
    - counter and list of events observed for actual session
    - recalculate anomaly level for actual session
    - recalculate threat level for actual session
    """

    session_tuple = "···".join([
            dict_line['SESSION ID'], dict_line['SRC_IP'], dict_line['DST_IP'],
            dict_line['PROTO'], dict_line['SRC_PORT'], dict_line['DST_PORT']
        ])

    priority = int(dict_line['priority'])

    if session_tuple not in sessions:
        sessions[session_tuple] = {}
        # store the session tuple values related to this new session_tuple:

        sessions[session_tuple]['events'] = []
        sessions[session_tuple]['anomaly_level'] = 0
        sessions[session_tuple]['threat_level'] = 0
        sessions[session_tuple]["counter"] = 0
        sessions[session_tuple]['max_prio'] = priority
        sessions[session_tuple]["bytes_sent"] = 0
        sessions[session_tuple]["bytes_received"] = 0
        sessions[session_tuple]['first_event_tstamp'] = int(event_tstamp)

    sessions[session_tuple]['last_event_tstamp'] = int(event_tstamp)
    sessions[session_tuple]["counter"] += 1

    if dict_line['type']=="TRAFFIC":
        sessions[session_tuple]["bytes_sent"] += int(dict_line['BYTES_SENT'])
        sessions[session_tuple]["bytes_received"] += int(dict_line['BYTES_RECEIVED'])

    if priority < sessions[session_tuple]['max_prio']:
    # lower prio value means more important (i.e., the most important priority is 1, or even 0 if priority=0 exists)
        sessions[session_tuple]['max_prio'] = priority
    else:
        sessions[session_tuple]['max_prio']

    if priority<=4 or (dict_line['type']=="TRAFFIC" and "end" not in event_descript and "start" not in event_descript):
        sessions[session_tuple]['anomaly_level'] += 1/priority
    if priority<=4 and dict_line['type']=="THREAT" and dict_line['ACTION']!="alert":
        sessions[session_tuple]['threat_level'] += 1/priority

    sessions[session_tuple]['events'].append("{}, {}".format(event_descript, dict_line['ACTION']))
\end{minted}

\section{Preprocesado para el clustering}\label{sec:preprocesado}

\section{Exploración de datos}\label{sec:exploraciondedatos}

\section{Selección de características}\label{sec:selecciondecaracteristicas}
